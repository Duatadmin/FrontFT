Replace the current MediaRecorder-based voice pipeline with a low-latency, format-controlled AudioWorklet-based pipeline that streams real-time Int16 PCM (16kHz, mono) audio to Deepgram via WebSocket. This ensures compatibility, removes format ambiguity, and improves transcription reliability.

ðŸ›  Migration Plan: MediaRecorder â†’ AudioWorklet
âœ… Phase 1 â€“ Preparation & Cleanup
Remove MediaRecorder Logic

Delete all references to new MediaRecorder(...), ondataavailable, and Blob-to-ArrayBuffer conversions.

Remove .webm saving logic (optional for debugging only).

Retain WebSocket + Transcript Handling

Keep the backend streaming logic and transcript message parsing as-is.

âœ… Phase 2 â€“ AudioWorklet Setup
Initialize AudioContext

ts
ÐšÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ
Ð ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ
const audioContext = new AudioContext({ sampleRate: 16000 });
Create AudioWorkletProcessor
File: pcm-processor.js
Purpose: Convert raw Float32Array microphone data to Int16Array PCM and post to main thread.

js
ÐšÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ
Ð ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ
class PCMProcessor extends AudioWorkletProcessor {
  process(inputs) {
    const input = inputs[0][0];
    if (!input) return true;
    const int16 = new Int16Array(input.length);
    for (let i = 0; i < input.length; i++) {
      const s = Math.max(-1, Math.min(1, input[i]));
      int16[i] = s * 0x7FFF;
    }
    this.port.postMessage(int16.buffer, [int16.buffer]);
    return true;
  }
}
registerProcessor('pcm-processor', PCMProcessor);
Register and Connect the Worklet

ts
ÐšÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ
Ð ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ
await audioContext.audioWorklet.addModule('pcm-processor.js');
const node = new AudioWorkletNode(audioContext, 'pcm-processor');
node.port.onmessage = (e) => {
  socket.send(e.data); // Send Int16 PCM buffer
};
const micStream = await navigator.mediaDevices.getUserMedia({ audio: true });
const source = audioContext.createMediaStreamSource(micStream);
source.connect(node);
node.connect(audioContext.destination);
âœ… Phase 3 â€“ Closing Stream Gracefully
Send Silence (Optional but Recommended)

ts
ÐšÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ
Ð ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ
const silence = new Int16Array(16000); // 1 second of silence
socket.send(silence.buffer);
Send CloseStream

ts
ÐšÐ¾Ð¿Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ
Ð ÐµÐ´Ð°ÐºÑ‚Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ
socket.send(JSON.stringify({ type: 'CloseStream' }));
âœ… Phase 4 â€“ Hook Refactoring
Update useVoiceAssistant.ts (or create useVoiceAssistantAudioWorklet.ts)

startRecording() â†’ sets up AudioContext, registers Worklet, starts stream.

stopRecording() â†’ disconnects, flushes silence, sends CloseStream.

Maintain mode, busy, transcript state handling.

âœ… Phase 5 â€“ Documentation Update
Update VOICE-MODULE.md with:

ðŸ“Š Audio pipeline: AudioContext â†’ AudioWorklet â†’ WebSocket

ðŸ§  Format: 16-bit PCM / 16kHz / Mono

ðŸ”Œ Supported browsers: Chrome, Edge, Firefox (Safari: limited)

ðŸ§ª Debug tips: Print Int16Array samples, log chunk sizes

ðŸ§  Optional Add-ons (Post-Migration)
Voice Activity Detection (VAD) integration using AnalyserNode or RMS thresholding.

Silence detection for walkie-talkie mode.

Chunk batching for smoother WebSocket performance.

Graceful fallback if AudioWorklet isn't supported.

âœ… Migration Success Criteria
Criteria	Target
Deepgram transcripts	Appear consistently (no empty)
SchemaError in logs	Fully eliminated
Audio format	Verified: Linear16 / 16kHz / mono
Latency	Sub-300ms (record-to-transcript)
WebSocket messages	Binary + valid CloseStream JSON